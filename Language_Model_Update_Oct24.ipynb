{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fc2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import heapq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a72670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Text Cleaner\n",
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zñáéíóúü]\", \" \", newString)\n",
    "    long_words=[]\n",
    "    for i in newString.split():\n",
    "        if len(i)>=3:\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7e138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('training_data.txt', 'r', encoding='utf-8') as file:\n",
    "    training_data = file.read()\n",
    "\n",
    "data_new = text_cleaner(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9736604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Creating Sequences\n",
    "def create_seq(text, length = 30):\n",
    "    sequences = list()\n",
    "    for i in range(length, len(text)):\n",
    "        seq = text[i-length:i+1]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = create_seq(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "450abd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Character Mapping\n",
    "chars = sorted(list(set(data_new)))\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "reverse_mapping = {i: c for c, i in mapping.items()}  # Reverse mapping for efficiency\n",
    "\n",
    "def encode_seq(seq):\n",
    "    sequences = list()\n",
    "    for line in seq:\n",
    "        encoded_seq = [mapping[char] for char in line]\n",
    "        sequences.append(encoded_seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = encode_seq(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14eca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preparing the dataset\n",
    "vocab = len(mapping)\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# 5. Defining the Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
    "model.add(GRU(150, dropout=0.1))\n",
    "model.add(Dense(vocab, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69ed232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3960/3960 [==============================] - 28s 6ms/step - loss: 1.9238 - acc: 0.4170 - val_loss: 2.1612 - val_acc: 0.3297 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.1143 - acc: 0.3478 - val_loss: 2.1027 - val_acc: 0.3549 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.1380 - acc: 0.3378 - val_loss: 2.0635 - val_acc: 0.3609 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 2.0785 - acc: 0.3610 - val_loss: 2.0289 - val_acc: 0.3752 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 2.0858 - acc: 0.3622 - val_loss: 2.0200 - val_acc: 0.3822 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 2.0798 - acc: 0.3645 - val_loss: 1.9856 - val_acc: 0.3888 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.0611 - acc: 0.3674 - val_loss: 2.0160 - val_acc: 0.3854 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.0667 - acc: 0.3692 - val_loss: 1.9954 - val_acc: 0.3947 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 2.0653 - acc: 0.3673 - val_loss: 1.9721 - val_acc: 0.3963 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.0639 - acc: 0.3699 - val_loss: 1.9961 - val_acc: 0.3859 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.0532 - acc: 0.3728 - val_loss: 1.9801 - val_acc: 0.3953 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 2.0683 - acc: 0.3655 - val_loss: 2.0080 - val_acc: 0.3788 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 2.0013 - acc: 0.3777 - val_loss: 1.9303 - val_acc: 0.4023 - lr: 0.0020\n",
      "Epoch 14/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9980 - acc: 0.3780 - val_loss: 1.9261 - val_acc: 0.4025 - lr: 0.0020\n",
      "Epoch 15/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9928 - acc: 0.3821 - val_loss: 1.9197 - val_acc: 0.4088 - lr: 0.0020\n",
      "Epoch 16/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9930 - acc: 0.3821 - val_loss: 1.9108 - val_acc: 0.4136 - lr: 0.0020\n",
      "Epoch 17/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9952 - acc: 0.3834 - val_loss: 1.9103 - val_acc: 0.4150 - lr: 0.0020\n",
      "Epoch 18/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9976 - acc: 0.3822 - val_loss: 1.9059 - val_acc: 0.4150 - lr: 0.0020\n",
      "Epoch 19/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9827 - acc: 0.3871 - val_loss: 1.8940 - val_acc: 0.4171 - lr: 0.0020\n",
      "Epoch 20/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9775 - acc: 0.3885 - val_loss: 1.8978 - val_acc: 0.4155 - lr: 0.0020\n",
      "Epoch 21/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9706 - acc: 0.3893 - val_loss: 1.8912 - val_acc: 0.4135 - lr: 0.0020\n",
      "Epoch 22/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9711 - acc: 0.3891 - val_loss: 1.8974 - val_acc: 0.4127 - lr: 0.0020\n",
      "Epoch 23/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9647 - acc: 0.3937 - val_loss: 1.8959 - val_acc: 0.4204 - lr: 0.0020\n",
      "Epoch 24/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9596 - acc: 0.3960 - val_loss: 1.8750 - val_acc: 0.4261 - lr: 0.0020\n",
      "Epoch 25/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9558 - acc: 0.3962 - val_loss: 1.8760 - val_acc: 0.4232 - lr: 0.0020\n",
      "Epoch 26/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9512 - acc: 0.3988 - val_loss: 1.8612 - val_acc: 0.4292 - lr: 0.0020\n",
      "Epoch 27/50\n",
      "3960/3960 [==============================] - 24s 6ms/step - loss: 1.9429 - acc: 0.4000 - val_loss: 1.8617 - val_acc: 0.4366 - lr: 0.0020\n",
      "Epoch 28/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9448 - acc: 0.4017 - val_loss: 1.8558 - val_acc: 0.4326 - lr: 0.0020\n",
      "Epoch 29/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9487 - acc: 0.3995 - val_loss: 1.8657 - val_acc: 0.4277 - lr: 0.0020\n",
      "Epoch 30/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9564 - acc: 0.3978 - val_loss: 1.8698 - val_acc: 0.4329 - lr: 0.0020\n",
      "Epoch 31/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9585 - acc: 0.3978 - val_loss: 1.8884 - val_acc: 0.4248 - lr: 0.0020\n",
      "Epoch 32/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9534 - acc: 0.3993 - val_loss: 1.8749 - val_acc: 0.4297 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "3960/3960 [==============================] - 23s 6ms/step - loss: 1.9494 - acc: 0.3999 - val_loss: 1.8691 - val_acc: 0.4299 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# 6. Training\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=False, monitor='val_loss'),\n",
    "             ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)]\n",
    "\n",
    "history = model.fit(X_tr, y_tr, epochs=50, batch_size=256, verbose=1, callbacks=callbacks, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c614336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Function for Text Generation using Beam Search\n",
    "def generate_seq_beam_search(model, mapping, seq_length, seed_text, n_chars, beam_width=3):\n",
    "    sequences = [{'seq': seed_text, 'score': 0.0}]\n",
    "    for _ in range(n_chars):\n",
    "        all_candidates = list()\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]['seq'], sequences[i]['score']\n",
    "            encoded = [mapping[char] for char in seq]\n",
    "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre').squeeze()\n",
    "            pred = model.predict(np.array([encoded]), verbose=0)\n",
    "            probas = np.exp(pred) / np.sum(np.exp(pred))\n",
    "            top_k = heapq.nlargest(beam_width, zip(probas[0], list(range(len(probas[0])))))\n",
    "            for j in range(len(top_k)):\n",
    "                score_, idx = top_k[j]\n",
    "                out_char = reverse_mapping[idx]\n",
    "                candidate = {'seq': seq + out_char, 'score': score - np.log(score_)}\n",
    "                all_candidates.append(candidate)\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup['score'], reverse=True)\n",
    "        sequences = ordered[:beam_width]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1a785eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juebes veinte tres de febrero de mil setecientosticatusesla veinienoco exle co\n"
     ]
    }
   ],
   "source": [
    "#Function Design for predicting missing text after a sentence\n",
    "seed_text = \"Juebes veinte tres de febrero de mil setecientos\".lower()\n",
    "num_chars_to_predict = 30\n",
    "results = generate_seq_beam_search(model, mapping, 30, seed_text, num_chars_to_predict)\n",
    "print(results[0]['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f3414ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juebes veintecla mosaceninatde mil setecientos\n"
     ]
    }
   ],
   "source": [
    "#Predicting missing text in a gap \n",
    "# Define the text before and after the gap\n",
    "text_before_gap = \"Juebes veinte\".lower()\n",
    "text_after_gap = \"de mil setecientos\".lower()\n",
    "\n",
    "# Estimate the gap length (this can be a rough estimate or based on context)\n",
    "# Here, I'm using an arbitrary value; adjust as needed\n",
    "gap_length_estimate = 15\n",
    "\n",
    "# Generate content for the gap\n",
    "results = generate_seq_beam_search(model, mapping, 30, text_before_gap, gap_length_estimate)\n",
    "predicted_gap_content = results[0]['seq'][len(text_before_gap):]\n",
    "\n",
    "# Merge the content\n",
    "completed_sentence = text_before_gap + predicted_gap_content + text_after_gap\n",
    "print(completed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c4375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
