{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fzYt9M9sffEF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import heapq\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, GRU, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data\\\\collection\\\\part2.txt\", \"r\", encoding=\"utf-8\") as infile:\n",
        "    for line in infile:\n",
        "        data_text = line\n",
        "        print(len(data_text))"
      ],
      "metadata": {
        "id": "Os5yME6ZgKWb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zñáéíóúü]\", \" \", newString)\n",
        "    long_words=[]\n",
        "    for i in newString.split():\n",
        "        if len(i)>=3:\n",
        "            long_words.append(i)\n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "data_new = text_cleaner(data_text)"
      ],
      "metadata": {
        "id": "ihN1SN8Qgwje"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Sequences\n",
        "def create_seq(text, length = 30):\n",
        "    sequences = list()\n",
        "    for i in range(length, len(text)):\n",
        "        seq = text[i-length:i+1]\n",
        "        sequences.append(seq)\n",
        "    return sequences\n",
        "\n",
        "sequences = create_seq(data_new)\n",
        "\n",
        "# Character Mapping\n",
        "chars = sorted(list(set(data_new)))\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "def encode_seq(seq):\n",
        "    sequences = list()\n",
        "    for line in seq:\n",
        "        encoded_seq = [mapping[char] for char in line]\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences\n",
        "\n",
        "sequences = encode_seq(sequences)\n"
      ],
      "metadata": {
        "id": "Hsg-zjuUhipr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the dataset\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# Defining the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
        "model.add(GRU(150, recurrent_dropout=0.1, dropout=0.1))\n",
        "model.add(Dense(vocab, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=Adam(learning_rate=0.01))\n",
        "\n",
        "# Training\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
        "             ModelCheckpoint('model.h5', save_best_only=True,\n",
        "             save_weights_only=False, monitor='val_loss')]\n",
        "\n",
        "history = model.fit(X_tr, y_tr, epochs=50, batch_size=256,\n",
        "                    verbose=1, callbacks=callbacks, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqQvrQV-hloC",
        "outputId": "68ac64e1-78b3-41b0-b769-8cbefe95d5f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.1780 - acc: 0.0556 - val_loss: 3.1405 - val_acc: 0.2778\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 3.1140 - acc: 0.1667 - val_loss: 3.0695 - val_acc: 0.2778\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 266ms/step - loss: 2.9597 - acc: 0.1358 - val_loss: 5.8885 - val_acc: 0.2778\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 281ms/step - loss: 4.9776 - acc: 0.1358 - val_loss: 3.3320 - val_acc: 0.0000e+00\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 2.8570 - acc: 0.1358 - val_loss: 3.1376 - val_acc: 0.0556\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 274ms/step - loss: 2.8911 - acc: 0.1728 - val_loss: 3.1380 - val_acc: 0.0556\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 272ms/step - loss: 2.9045 - acc: 0.1667 - val_loss: 3.1278 - val_acc: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for text generation using beam search\n",
        "def generate_seq_beam_search(model, mapping, seq_length, seed_text, n_chars, beam_width=3):\n",
        "    sequences = [{'seq': seed_text, 'score': 0.0}]\n",
        "    for _ in range(n_chars):\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]['seq'], sequences[i]['score']\n",
        "            encoded = [mapping[char] for char in seq]\n",
        "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre').squeeze()\n",
        "            pred = model.predict(np.array([encoded]), verbose=0)\n",
        "            probas = np.exp(pred) / np.sum(np.exp(pred))\n",
        "            top_k = heapq.nlargest(beam_width, zip(probas[0], list(range(len(probas[0])))))\n",
        "            for j in range(len(top_k)):\n",
        "                score_, idx = top_k[j]\n",
        "                out_char = ''\n",
        "                for char, index in mapping.items():\n",
        "                    if index == idx:\n",
        "                        out_char = char\n",
        "                        break\n",
        "                candidate = {'seq': seq + out_char, 'score': score - np.log(score_)}\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup:tup['score'])\n",
        "        sequences = ordered[:beam_width]\n",
        "    return sequences\n"
      ],
      "metadata": {
        "id": "sKYj_MTkhwCL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "print(generate_seq_beam_search(model, mapping, 30, \"Juebes veinte tres de febrero de mil setecientos\".lower(), 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJepFgGnh02z",
        "outputId": "e2bc2b10-4771-4e37-ae7b-1d613acc0432"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'seq': 'juebes veinte tres de febrero de mil setecientos aanos anoosa a', 'score': 47.24448323249817}, {'seq': 'juebes veinte tres de febrero de mil setecientos aanos aa ara a', 'score': 47.247785329818726}, {'seq': 'juebes veinte tres de febrero de mil setecientos aanos anooseno', 'score': 47.249215841293335}]\n"
          ]
        }
      ]
    }
  ]
}