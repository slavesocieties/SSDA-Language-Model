{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbBSSFn8Kq4Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import heapq\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 1. Text Cleaner\n",
        "def text_cleaner(text):\n",
        "    newString = text.lower()\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "    newString = re.sub(\"[^a-zñáéíóúü]\", \" \", newString)\n",
        "    long_words=[]\n",
        "    for i in newString.split():\n",
        "        if len(i)>=3:\n",
        "            long_words.append(i)\n",
        "    return (\" \".join(long_words)).strip()\n",
        "\n",
        "# Use the function to clean the data\n",
        "data_new = text_cleaner(data_text)\n",
        "\n",
        "# 2. Creating Sequences\n",
        "def create_seq(text, length = 30):\n",
        "    sequences = list()\n",
        "    for i in range(length, len(text)):\n",
        "        seq = text[i-length:i+1]\n",
        "        sequences.append(seq)\n",
        "    return sequences\n",
        "\n",
        "sequences = create_seq(data_new)\n",
        "\n",
        "# 3. Character Mapping\n",
        "chars = sorted(list(set(data_new)))\n",
        "mapping = dict((c, i) for i, c in enumerate(chars))\n",
        "reverse_mapping = {i: c for c, i in mapping.items()}  # Reverse mapping for efficiency\n",
        "\n",
        "def encode_seq(seq):\n",
        "    sequences = list()\n",
        "    for line in seq:\n",
        "        encoded_seq = [mapping[char] for char in line]\n",
        "        sequences.append(encoded_seq)\n",
        "    return sequences\n",
        "\n",
        "sequences = encode_seq(sequences)\n",
        "\n",
        "# 4. Preparing the dataset\n",
        "vocab = len(mapping)\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab)\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# 5. Defining the Model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab, 50, input_length=30, trainable=True))\n",
        "model.add(GRU(150, dropout=0.1))\n",
        "model.add(Dense(vocab, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer=Adam(learning_rate=0.01))\n",
        "\n",
        "# 6. Training\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
        "             ModelCheckpoint('model.h5', save_best_only=True, save_weights_only=False, monitor='val_loss'),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)]\n",
        "\n",
        "history = model.fit(X_tr, y_tr, epochs=50, batch_size=256, verbose=1, callbacks=callbacks, validation_data=(X_val, y_val))\n",
        "\n",
        "# 7. Function for Text Generation using Beam Search\n",
        "def generate_seq_beam_search(model, mapping, seq_length, seed_text, n_chars, beam_width=3):\n",
        "    sequences = [{'seq': seed_text, 'score': 0.0}]\n",
        "    for _ in range(n_chars):\n",
        "        all_candidates = list()\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]['seq'], sequences[i]['score']\n",
        "            encoded = [mapping[char] for char in seq]\n",
        "            encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre').squeeze()\n",
        "            pred = model.predict(np.array([encoded]), verbose=0)\n",
        "            probas = np.exp(pred) / np.sum(np.exp(pred))\n",
        "            top_k = heapq.nlargest(beam_width, zip(probas[0], list(range(len(probas[0])))))\n",
        "            for j in range(len(top_k)):\n",
        "                score_, idx = top_k[j]\n",
        "                out_char = reverse_mapping[idx]\n",
        "                candidate = {'seq': seq + out_char, 'score': score - np.log(score_)}\n",
        "                all_candidates.append(candidate)\n",
        "        ordered = sorted(all_candidates, key=lambda tup:tup['score'], reverse=True)\n",
        "        sequences = ordered[:beam_width]\n",
        "    return sequences\n",
        "\n",
        "# Testing the sequence generation\n",
        "results = generate_seq_beam_search(model, mapping, 30, \"Juebes veinte tres de febrero de mil setecientos\".lower(), 15)\n",
        "print(results[0]['seq'])\n"
      ]
    }
  ]
}